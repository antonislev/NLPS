✍️ AUTHOR
[ΛΕΒΕΙΔΙΩΤΗΣ ΑΝΤΩΝΗΣ]
Τμήμα Πληροφορικής, [Πανεπιστήμιο Πειραιώς]
Έτος: 2025
ΑΜ : Π22084

## 📌 Περιγραφή Έργου

Η εργασία αυτή εστιάζει στην ανακατασκευή δύο μη δομημένων αγγλικών κειμένων με στόχο τη μετατροπή τους σε καθαρές, κατανοητές και σωστά δομημένες εκδοχές. Για την επίτευξη του στόχου αξιοποιούνται:

1. Ένας custom finite state automaton (FSA)
2. Τρεις διαφορετικές αυτόματες βιβλιοθήκες NLP (transformer pipelines)
3. Τεχνικές αξιολόγησης (Cosine Similarity, BLEU, χειροκίνητη αξιολόγηση)
4. Υπολογιστική ανάλυση ενσωματώσεων λέξεων (Word2Vec, GloVe, FastText, BERT)

---

## 🧠 Σημασία της Σημασιολογικής Ανακατασκευής

Η σημασιολογική ανακατασκευή:

- Διευκολύνει την **κατανόηση περίπλοκων ή κακογραμμένων προτάσεων**
- Βελτιώνει την **αναγνωσιμότητα** και **ποιότητα περιεχομένου**
- Μπορεί να χρησιμοποιηθεί σε εφαρμογές όπως:
  - Επαναδιατύπωση κειμένων (paraphrasing)
  - Αυτόματη σύνοψη (summarization)
  - Ανίχνευση λογοκλοπής
  - Εκπαίδευση AI σε “καθαρά” δεδομένα

---

## ⚙️ Εφαρμογή Τεχνικών NLP

Χρησιμοποιήθηκαν σύγχρονες μέθοδοι NLP:

- **Καθαρισμός Κειμένου**: αφαίρεση θορύβου και επιδιόρθωση σφαλμάτων
- **Σημασιολογική Ανάλυση**: με χρήση BERT και Sentence Transformers
- **Παραφραστικά Μοντέλα**: όπως `T5`, `BART`, `PEGASUS` για την ανακατασκευή
- **Αξιολόγηση Νοηματικής Ομοιότητας**: με cosine similarity ή BERTScore

---


## ✅ Παραδοτέο 1: Ανακατασκευή Κειμένου

### A. Ανακατασκευή 2 Προτάσεων με Custom FSA

Αναπτύξαμε έναν απλό Finite State Automaton (FSA) σε Python με στόχο την αναγνώριση λέξεων-κλειδιών και την ανασύνθεση ασαφών προτάσεων με βασικούς μορφοσυντακτικούς κανόνες.

**Παραδείγματα Ανακατασκευής:**

| Είσοδος | Έξοδος |
|--------|--------|
| `Today is our dragon boat festival...` | `Today we celebrate the Dragon Boat Festival, an important day in Chinese culture.` |
| `I am very appreciated the full support of the professor...` | `I appreciate the professor's support for our publication in the Springer proceedings.` |

**Παρατηρήσεις:**  
Το μοντέλο αυτό αποδίδει καλά σε στοχευμένες περιπτώσεις με συγκεκριμένα μοτίβα, αν και έχει περιορισμούς σε γενίκευση.

---

### B. Ανακατασκευή με Χρήση 3 NLP Pipelines

Εφαρμόστηκαν τρία διαφορετικά transformer-based μοντέλα της Hugging Face:

| Βιβλιοθήκη | Περιγραφή |
|-----------|-----------|
| `T5 Paraphraser (Vamsi/T5-paraphraser)` | Παραγωγή συντακτικά σωστών παραφράσεων |
| `Pegasus Summarizer (google/pegasus-xsum)` | Σύνοψη και καθαρισμός προτάσεων |
| `GPT-Neo (EleutherAI/gpt-neo-1.3B)` | Δημιουργική αναδόμηση μέσω prompt-based παραγωγής |

**Κύρια Παρατηρήσεις:**

- **T5:** Παρήγαγε πιστές και σωστά δομημένες εκδοχές.
- **Pegasus:** Παρείχε περιληπτικές εκδοχές, αλλά μερικές λεπτομέρειες χάθηκαν.
- **GPT-Neo:** Δημιουργικότητα στη σύνταξη, αλλά πιθανότητα αλλοίωσης πληροφορίας.

---

### C. Σύγκριση Προσεγγίσεων

Αξιολογήθηκαν οι ανακατασκευές με τρεις μεθόδους:

#### 🔹 Cosine Similarity

Χρήση TF-IDF και word embeddings για υπολογισμό ομοιότητας:

- Υψηλή συνάφεια παρατηρήθηκε με FSA όταν βασιζόταν σε keywords.

#### 🔹 BLEU Score

- Μέτρια σκορ, ιδιαίτερα για FSA λόγω απουσίας στατιστικής εκμάθησης.

#### 🔹 Χειροκίνητη Αξιολόγηση

- FSA: ευανάγνωστα αλλά περιορισμένα.
- Transformers: μεγαλύτερη φυσικότητα και συντακτική ποικιλία.

**Συμπεράσματα:**

- Το FSA είναι χρήσιμο για συγκεκριμένες περιπτώσεις.
- Η T5 είναι αξιόπιστη για επαγγελματική αναδιατύπωση.
- Η cosine similarity είναι πιο συνεπής σε σημασιολογική αξιολόγηση από BLEU.
- Η επιλογή εργαλείου εξαρτάται από το ζητούμενο: ακρίβεια ή δημιουργικότητα.

---

## 🔍 Παραδοτέο 2: Υπολογιστική Ανάλυση

Σκοπός αυτής της ενότητας είναι η υπολογιστική αξιολόγηση των εκδοχών κειμένου με τεχνικές embeddings και ανάλυση σημασιολογικού χώρου.

### 🔹 Pipelines Ενσωμάτωσης Λέξεων

| Μέθοδος | Περιγραφή |
|--------|-----------|
| **Word2Vec** | GoogleNews vectors, μέσο διάνυσμα πρότασης |
| **GloVe** | Stanford embeddings (Common Crawl, 300d) |
| **FastText** | Facebook AI, πλεονέκτημα στις υπολέξεις |
| **BERT** | HuggingFace `bert-base-uncased`, [CLS] mean pooling |
| **Custom NLP Pipeline** | Χειροποίητη ροή με Word2Vec + WordNet + NLTK concept trees |

### 🔹 Cosine Similarity (με Sentence-BERT)

| Κείμενο | Similarity Score |
|--------|------------------|
| Κείμενο 1 | 0.3951 |
| Κείμενο 2 | 0.6561 |

### 🔹 Οπτικοποίηση

- **PCA:** Μείωση διαστάσεων για επισκόπηση.
- **t-SNE:** Παρουσίασε συσπειρωμένες (clustered) εκδοχές μετά την ανακατασκευή.

**Ανάλυση:**

- Οι αρχικές εκδοχές ήταν διασκορπισμένες στον σημασιολογικό χώρο.
- Οι ανακατασκευασμένες προτάσεις εμφάνισαν εννοιολογική συνοχή.
- Το BERT έδωσε την πιο καθαρή αναπαράσταση σημασιολογικών σχέσεων.

---
## ✅ Πόσο καλά αποτυπώθηκε το νόημα;

- Τα **context-aware embeddings** (BERT, RoBERTa) πέτυχαν **υψηλό βαθμό κατανόησης** του αρχικού νοήματος.
- Οι προτάσεις με **σαφή δομή και καθαρά συμφραζόμενα** ανακατασκευάστηκαν με μεγάλη ακρίβεια.
- Η χρήση **στατικών ενσωματώσεων (Word2Vec)** είχε περιορισμούς, κυρίως σε πολυσημία και εκφράσεις.

---

## 🚧 Προκλήσεις στην Ανακατασκευή

| Πρόκληση | Περιγραφή |
|----------|-----------|
| Πολυσημία | Δυσκολία στην αποσαφήνιση λέξεων χωρίς συμφραζόμενα |
| Σύνθετες συντακτικές δομές | Μακροπερίοδες ή μη ολοκληρωμένες προτάσεις |
| Διατήρηση ύφους | Απαιτείται ισορροπία μεταξύ νοήματος και φυσικής ροής |
| Σπάνιο λεξιλόγιο | Ειδικοί όροι μπορεί να παραφραστούν λανθασμένα |

---

## 🤖 Αυτοματοποίηση με NLP

Η διαδικασία αυτοματοποιείται ως εξής:

1. **Προεπεξεργασία**: καθαρισμός, tokenization
2. **Semantic Chunking**: εντοπισμός νοηματικών μονάδων
3. **Ανακατασκευή**: χρήση μοντέλων όπως T5 ή GPT-3.5
4. **Αξιολόγηση**: cosine similarity ή BERTScore
5. **Τελική Βελτιστοποίηση**: χρήση grammar/style checker

---

## 📊 Συγκριτική Αξιολόγηση Τεχνικών

| Τεχνική / Μοντέλο | Πλεονεκτήματα | Μειονεκτήματα |
|-------------------|----------------|----------------|
| Word2Vec / GloVe | Ταχύτητα, ελαφριά | Όχι context-aware |
| BERT / RoBERTa | Σημασιολογική ευαισθησία | Απαιτεί υπολογιστική ισχύ |
| T5 / BART / GPT | Εξαιρετικό paraphrasing | Κίνδυνος αλλοίωσης νοήματος |
| Pegasus | Πολύ καλό σε σύνοψη & ανακατασκευή | Όχι κατάλληλο για κάθε ύφος |

---

## 🧠 Συμπεράσματα

- Η ανακατασκευή κειμένων βελτιώνει αισθητά τη συνοχή και σαφήνεια.
- Οι μοντέρνες NLP pipelines είναι ιδιαίτερα αποτελεσματικές, με τις T5 και BERT να υπερέχουν.
- Οι visualizations (PCA/t-SNE) τεκμηριώνουν τη βελτίωση στη σημασιολογική εγγύτητα.
- Η δημιουργία custom pipelines προσφέρει εννοιολογικό έλεγχο και κατανόηση των ενσωματώσεων.

---

##

## 📁 Requirments
transformers
scikit-learn
matplotlib
seaborn
nltk
gensim
pandas
numpy

